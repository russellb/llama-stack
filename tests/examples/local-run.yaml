built_at: '2024-09-23T00:54:40.551416'
image_name: local
docker_image: null
conda_env: local
apis_to_serve:
- shields
- agents
- models
- memory
- memory_banks
- inference
- safety
api_providers:
  inference:
    providers:
    - meta-reference
  safety:
    providers:
    - meta-reference
  agents:
    provider_type: meta-reference
    config:
      persistence_store:
        namespace: null
        type: sqlite
        db_path: /home/xiyan/.llama/runtime/kvstore.db
  memory:
    providers:
    - meta-reference
  telemetry:
    provider_type: meta-reference
    config: {}
routing_table:
  inference:
  - provider_type: meta-reference
    config:
      model: Llama3.1-8B-Instruct
      quantization: null
      torch_seed: null
      max_seq_len: 4096
      max_batch_size: 1
    routing_key: Llama3.1-8B-Instruct
  safety:
  - provider_type: meta-reference
    config:
      llama_guard_shield:
        model: Llama-Guard-3-1B
        excluded_categories: []
        disable_input_check: false
        disable_output_check: false
      prompt_guard_shield:
        model: Prompt-Guard-86M
    routing_key: ["llama_guard", "code_scanner_guard", "injection_shield", "jailbreak_shield"]
  memory:
  - provider_type: meta-reference
    config: {}
    routing_key: vector
